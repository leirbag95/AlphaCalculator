{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProjetML.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jDjEq2mY_lWm",
        "zctBgZFKJIzM",
        "gLJHg7AFw1jO",
        "6Aglc1cARZYw",
        "TBfMI521xhlE"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leirbag95/AlphaCalculator/blob/master/ProjetML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Guypkla-Zxt3",
        "colab_type": "text"
      },
      "source": [
        "## **Pré-requis**\n",
        "\n",
        "*   Charger tout le data préprocessing **dans l'ordre** avant de lancer un modèle\n",
        "*   Pour tester un modèle, envoyer tout le dataset d'évaluation sans certaine colonnnes\n",
        "*   Si l'import d'une library ne fonctionne pas, retirer le commentaire juste au dessus de celui-ci\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzz1fFzXb19W",
        "colab_type": "text"
      },
      "source": [
        "**Liste de tous les imports nécessaires**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg9aguW1aOpF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# libraries\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tag import UnigramTagger\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "nltk.download('sentiwordnet')\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "from nltk.tokenize import regexp_tokenize\n",
        "!pip3 install vaderSentiment\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from nltk.stem import PorterStemmer\n",
        "!pip3 install textblob\n",
        "from textblob import TextBlob\n",
        "from textblob import Word\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksUXIOjjcAi8",
        "colab_type": "text"
      },
      "source": [
        "**Chargement du dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shqh0PhIcHNH",
        "colab_type": "text"
      },
      "source": [
        "Chargement du dataset via le drive.google.\n",
        "Le résultat attendu après execution de la commande est:\n",
        "\n",
        "`Dataframe crée `"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVsVmHXCcENN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try: \n",
        "  global_df = pd.read_csv(\"http://christophe-rodrigues.fr/hotel_reviews.csv\", sep=';')\n",
        "  eval_data = pd.read_csv(\"http://christophe-rodrigues.fr/eval_reviews.csv\", sep=';')\n",
        "  print(\"Dataframe crée\")\n",
        "except Exception as e:\n",
        "  print(\"Une erreur a eu lieu lors du chargement du dataset\")\n",
        "  print(e)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93zbe98oc_kP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# on renomme le nom des colonnes\n",
        "global_df = global_df.rename(columns=({'Unnamed: 0':'id','reviews.rating':'rate','reviews.text':'review'}))\n",
        "eval_data = global_df.rename(columns=({'Unnamed: 0':'id','reviews.rating':'rate','reviews.text':'review'}))\n",
        "global_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahDA2z_Todzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "global_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIBn2tAJsCxT",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUXMvaW2sGC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df0 = global_df.copy()\n",
        "df_eval = eval_data.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExtC7ALkFhH2",
        "colab_type": "text"
      },
      "source": [
        "### **Data Cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3JXMPGdyJ4i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df0.insert(3,'review.cleaned', \"\")\n",
        "df0.insert(2,'is_good_review',0)\n",
        "df_eval.insert(3,'review.cleaned', \"\")\n",
        "df_eval.insert(2,'is_good_review',0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6LMGzPpy24w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# return the wordnet object value corresponding to the POS tag\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "def get_wordnet_pos(pos_tag):\n",
        "    if pos_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif pos_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif pos_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif pos_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "    \n",
        "import string\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "def clean_text(text):\n",
        "    # lower text\n",
        "    text = text.lower()\n",
        "    # tokenize text and remove puncutation\n",
        "    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n",
        "    # remove words that contain numbers\n",
        "    text = [word for word in text if not any(c.isdigit() for c in word)]\n",
        "    # remove stop words\n",
        "    stop = stopwords.words('english')\n",
        "    text = [x for x in text if x not in stop]\n",
        "    # remove empty tokens\n",
        "    text = [t for t in text if len(t) > 0]\n",
        "    # pos tag text\n",
        "    pos_tags = pos_tag(text)\n",
        "    # lemmatize text\n",
        "    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n",
        "    # remove words with only one letter\n",
        "    text = [t for t in text if len(t) > 1]\n",
        "    # join all\n",
        "    text = \" \".join(text)\n",
        "    return(text)\n",
        "\n",
        "# ajoute de la variable is_good_review\n",
        "def is_good_review(rate):\n",
        "  if rate > 2.5:\n",
        "    return 1\n",
        "  return 0\n",
        "# clean text data\n",
        "df0[\"review.cleaned\"] = df0[\"review\"].apply(lambda x: clean_text(x))\n",
        "df0[\"is_good_review\"] = df0[\"rate\"].apply(lambda x: is_good_review(x) )\n",
        "df_eval[\"review.cleaned\"] = df0[\"review\"].apply(lambda x: clean_text(x))\n",
        "df_eval[\"is_good_review\"] = df0[\"rate\"].apply(lambda x: is_good_review(x) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_guETRsyi0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfshuf0 = df0.copy().sample(frac=1)\n",
        "dfshuf_eval = df_eval.copy().sample(frac=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HvGxfZzR6_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = dfshuf0[dfshuf0['review'] == \"MoreMore\"].shape[0]\n",
        "dfshuf0 = dfshuf0.drop(dfshuf0[dfshuf0.review == \"MoreMore\"].sample(n = n).index, axis=0)\n",
        "n = dfshuf_eval[dfshuf_eval['review'] == \"MoreMore\"].shape[0]\n",
        "dfshuf_eval = dfshuf_eval.drop(dfshuf_eval[dfshuf_eval.review == \"MoreMore\"].sample(n = n).index, axis=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzrD5--vMwI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfshuf_eval.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJnIYGMUzywA",
        "colab_type": "text"
      },
      "source": [
        "### **Feature engineering**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5zmTF0hztKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add sentiment anaylsis columns\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "dfshuf0[\"sentiments\"] = dfshuf0[\"review.cleaned\"].apply(lambda x: sid.polarity_scores(x))\n",
        "dfshuf0 = pd.concat([dfshuf0.drop(['sentiments'], axis=1), dfshuf0['sentiments'].apply(pd.Series)], axis=1)\n",
        "dfshuf_eval[\"sentiments\"] = dfshuf_eval[\"review.cleaned\"].apply(lambda x: sid.polarity_scores(x))\n",
        "dfshuf_eval = pd.concat([dfshuf_eval.drop(['sentiments'], axis=1), dfshuf_eval['sentiments'].apply(pd.Series)], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tpFqPlc0pv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ajout du nombre de character à chaque colonne\n",
        "dfshuf0[\"nb_chars\"] = dfshuf0[\"review\"].apply(lambda x: len(x))\n",
        "\n",
        "# Ajout du nombre de mots à chaque colonne\n",
        "dfshuf0[\"nb_words\"] = dfshuf0[\"review\"].apply(lambda x: len(x.split(\" \")))\n",
        "\n",
        "# Ajout du nombre de character à chaque colonne\n",
        "dfshuf_eval[\"nb_chars\"] = dfshuf_eval[\"review\"].apply(lambda x: len(x))\n",
        "\n",
        "# Ajout du nombre de mots à chaque colonne\n",
        "dfshuf_eval[\"nb_words\"] = dfshuf_eval[\"review\"].apply(lambda x: len(x.split(\" \")))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEmrlBsS1dF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create doc2vec vector columns\n",
        "from gensim.test.utils import common_texts\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(dfshuf0[\"review.cleaned\"].apply(lambda x: x.split(\" \")))]\n",
        "documents_eval = [TaggedDocument(doc, [i]) for i, doc in enumerate(dfshuf_eval[\"review.cleaned\"].apply(lambda x: x.split(\" \")))]\n",
        "\n",
        "# train a Doc2Vec model with our text data\n",
        "model = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)\n",
        "model_eval = Doc2Vec(documents_eval, vector_size=5, window=2, min_count=1, workers=4)\n",
        "\n",
        "# transform each document into a vector data\n",
        "doc2vec_df = dfshuf0[\"review.cleaned\"].apply(lambda x: model.infer_vector(x.split(\" \"))).apply(pd.Series)\n",
        "doc2vec_df_eval = dfshuf_eval[\"review.cleaned\"].apply(lambda x: model_eval.infer_vector(x.split(\" \"))).apply(pd.Series)\n",
        "doc2vec_df.columns = [\"doc2vec_vector_\" + str(x) for x in doc2vec_df.columns]\n",
        "doc2vec_df_eval.columns = [\"doc2vec_vector_\" + str(x) for x in doc2vec_df_eval.columns]\n",
        "dfshuf0 = pd.concat([dfshuf0, doc2vec_df], axis=1)\n",
        "dfshuf_eval = pd.concat([dfshuf_eval, doc2vec_df_eval], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEjQe2h512pJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add tf-idfs columns\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(min_df = 10)\n",
        "tfidf_result = tfidf.fit_transform(dfshuf0[\"review.cleaned\"]).toarray()\n",
        "tfidf_df = pd.DataFrame(tfidf_result, columns = tfidf.get_feature_names())\n",
        "tfidf_df.columns = [\"word_\" + str(x) for x in tfidf_df.columns]\n",
        "tfidf_df.index = dfshuf0.index\n",
        "dfshuf0 = pd.concat([dfshuf0, tfidf_df], axis=1)\n",
        "\n",
        "tfidf_result = tfidf.fit_transform(dfshuf_eval[\"review.cleaned\"]).toarray()\n",
        "tfidf_df = pd.DataFrame(tfidf_result, columns = tfidf.get_feature_names())\n",
        "tfidf_df.columns = [\"word_\" + str(x) for x in tfidf_df.columns]\n",
        "tfidf_df.index = dfshuf_eval.index\n",
        "dfshuf_eval = pd.concat([dfshuf_eval, tfidf_df], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xnCSogc09ys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfshuf0.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZwT-T4LFXgm",
        "colab_type": "text"
      },
      "source": [
        "### **Data exploration**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4K2w3DZ9oAn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Montre la distribution des notes \n",
        "\n",
        "balanced0 = dfshuf0[\"rate\"].value_counts(normalize = True)\n",
        "balanced0.plot(kind='bar', title='Count (target)');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zb-zNbS0quEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# equilibrage du dataset\n",
        "for i in [4,3,5]:\n",
        "  ratio = dfshuf_eval['rate'].value_counts()[2]/(dfshuf_eval['rate'].value_counts()[i])\n",
        "  n = dfshuf_eval[\"rate\"].value_counts()[i] - int(dfshuf_eval[\"rate\"].value_counts()[i]*ratio)\n",
        "  rows = dfshuf_eval[dfshuf_eval[\"rate\"] == i].sample(n = n)\n",
        "  dfshuf_eval = dfshuf_eval.drop(rows.index,axis=0)\n",
        "# equilibrage du dataset\n",
        "\n",
        "for i in [4,3,5]:\n",
        "  ratio = dfshuf0['rate'].value_counts()[2]/(dfshuf0['rate'].value_counts()[i])\n",
        "  n = dfshuf0[\"rate\"].value_counts()[i] - int(dfshuf0[\"rate\"].value_counts()[i]*ratio)\n",
        "  rows = dfshuf0[dfshuf0[\"rate\"] == i].sample(n = n)\n",
        "  dfshuf0 = dfshuf0.drop(rows.index,axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-0Qh4iaUT4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Montre la distribution des notes \n",
        "\n",
        "balanced1 = dfshuf0[\"rate\"].value_counts(normalize = True)\n",
        "balanced1.plot(kind='bar', title='Count (target)');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gymq4Zx_2Tlz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# wordcloud function\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_wordcloud(data, title = None):\n",
        "    wordcloud = WordCloud(\n",
        "        background_color = 'white',\n",
        "        max_words = 200,\n",
        "        max_font_size = 40, \n",
        "        scale = 3,\n",
        "        random_state = 42\n",
        "    ).generate(str(data))\n",
        "\n",
        "    fig = plt.figure(1, figsize = (20, 20))\n",
        "    plt.axis('off')\n",
        "    if title: \n",
        "        fig.suptitle(title, fontsize = 20)\n",
        "        fig.subplots_adjust(top = 2.3)\n",
        "\n",
        "    plt.imshow(wordcloud)\n",
        "    plt.show()\n",
        "    \n",
        "# print wordcloud\n",
        "show_wordcloud(dfshuf0[\"review.cleaned\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOV28e2A27wC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Les reviews les plus positives (plus de 5 mots minimum)\n",
        "dfshuf0.sort_values(\"pos\", ascending = False)[[\"rate\",\"review\", \"pos\",\"nb_words\"]].head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVycDzRKHj1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Les reviews les plus négatives (plus de 5 mots minimum)\n",
        "dfshuf0.sort_values(\"neg\", ascending = False)[[\"rate\",\"review\", \"neg\", \"nb_words\"]].head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cyblbDO3pv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Les reviews les plus objectives (plus de 5 mots minimum)\n",
        "dfshuf0.sort_values(\"neu\", ascending = False)[[\"rate\",\"review\", \"neu\", \"nb_words\"]].head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p-VbogSVDU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Les reviews les plus objectives (plus de 5 mots minimum)\n",
        "dfshuf0[dfshuf0[\"rate\"] == 3].sort_values(\"neu\", ascending = False)[[\"rate\",\"review\", \"neu\", \"nb_words\"]].head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHclyNJ3IUka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot sentiment distribution for positive and negative reviews\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "for x in [1,2,3,4,5]:\n",
        "    subset = dfshuf0[dfshuf0['rate'] == x]\n",
        "    \n",
        "    # Draw the density plot\n",
        "    label = str(x)\n",
        "    sns.distplot(subset['compound'], hist = False, label = label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7rNLkjIPWzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot sentiment distribution for positive and negative reviews\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "for x in [0,1]:\n",
        "    subset = dfshuf0[dfshuf0['is_good_review'] == x]\n",
        "    \n",
        "    # Draw the density plot\n",
        "    label = str(x)\n",
        "    sns.distplot(subset['compound'], hist = False, label = label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm0ZumrAM81N",
        "colab_type": "text"
      },
      "source": [
        "# Modeling `is_good_review`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kcsASomR_oe",
        "colab_type": "text"
      },
      "source": [
        "## Prediction based on `compound`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fw4lMjjSG8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "On predit la note à l'aide du calcule de sentiments.\n",
        "Le résultat obtenu est un chiffre compris dans l'intervalle [-1;1] qu'on normalise dans [1;5]\n",
        "\"\"\"\n",
        "def predict_classifier_rate(compound): \n",
        "  final_rate = 2.5 * compound + 2.5\n",
        "  if final_rate > 2.5:\n",
        "    return 1\n",
        "  return 0\n",
        "\n",
        "def get_score_classifier(data):\n",
        "  mean = 0\n",
        "  divisor = data.shape[0]\n",
        "  for i in range(divisor):\n",
        "    rate = predict_classifier_rate(data['compound'][i])\n",
        "    if rate == data['is_good_review'][i]:\n",
        "      mean += 1\n",
        "  return mean / divisor\n",
        "\n",
        "\n",
        "# FIXME: problème d'index\n",
        "print(get_score_classifier(dfshuf_eval))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_9K5KevNBdk",
        "colab_type": "text"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8bEwwHANH0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logistic_regression(df_eval):\n",
        "  label = \"is_good_review\"\n",
        "  ignore_cols = [label,\"rate\", \"review\", \"review.cleaned\", \"id\"]\n",
        "  features = [c for c in dfshuf0.columns if c not in ignore_cols]\n",
        "  # split the data into train and test\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  X_train, X_test, y_train, y_test = train_test_split(dfshuf0[features], dfshuf0[label], test_size = 0.20, random_state = 42)\n",
        "  # train a logitstic regression classifier\n",
        "  lr = LogisticRegression()\n",
        "  lr.fit(X_train, y_train)\n",
        "  y_pred = lr.predict(df_eval)\n",
        "  return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-z1qQzv7gpf",
        "colab_type": "text"
      },
      "source": [
        "### Résultats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4na8o5ePr3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "label = \"is_good_review\"\n",
        "ignore_cols = [label,\"rate\", \"review\", \"review.cleaned\",\"id\"]\n",
        "features = [c for c in dfshuf_eval.columns if c not in ignore_cols]\n",
        "X_dfshuf_eval = dfshuf_eval[features]\n",
        "y_dfshuf_eval = dfshuf_eval[label]\n",
        "eval_predicted = logistic_regression(X_dfshuf_eval)\n",
        "print(mean_squared_error(eval_predicted,y_dfshuf_eval))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM_f-85uPiae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ROC curve\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_pred = eval_predicted\n",
        "fpr, tpr, thresholds = roc_curve(y_dfshuf_eval, y_pred, pos_label = 1)\n",
        "\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(1, figsize = (15, 10))\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color='darkorange',\n",
        "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.0])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1BXSgApQgg-",
        "colab_type": "text"
      },
      "source": [
        "## RandomForest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUfWZmppQpeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_forest(df_eval):\n",
        "  # on lance la logistic regression sur les 2 dataset: dfshuf1 et dfshuf0\n",
        "  label = \"is_good_review\"\n",
        "  ignore_cols = [label,\"rate\", \"review\", \"review.cleaned\", \"id\"]\n",
        "  features = [c for c in dfshuf0.columns if c not in ignore_cols]\n",
        "  # split the data into train and test\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  \n",
        "  X_train, X_test, y_train, y_test = train_test_split(dfshuf0[features], dfshuf0[label], test_size = 0.20, random_state = 42)\n",
        "  # train a random forest classifier\n",
        "  rf = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
        "  rf.fit(X_train, y_train)\n",
        "  y_pred = rf.predict(df_eval)\n",
        "  return y_pred\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvDXrh9x71zg",
        "colab_type": "text"
      },
      "source": [
        "### Résultats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOrCGspe77B-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "label = \"is_good_review\"\n",
        "ignore_cols = [label,\"rate\", \"review\", \"review.cleaned\", \"id\"]\n",
        "features = [c for c in dfshuf_eval.columns if c not in ignore_cols]\n",
        "X_dfshuf_eval = dfshuf_eval[features]\n",
        "y_dfshuf_eval = dfshuf_eval[label]\n",
        "eval_predicted = random_forest(X_dfshuf_eval)\n",
        "print(mean_squared_error(eval_predicted,y_dfshuf_eval))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCxAodbltEDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# show feature importance\n",
        "feature_importances_df = pd.DataFrame({\"feature\": features, \"importance\": rf.feature_importances_}).sort_values(\"importance\", ascending = False)\n",
        "feature_importances_df.head(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKXFnCGnRLax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ROC curve\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_pred = eval_predicted\n",
        "fpr, tpr, thresholds = roc_curve(y_dfshuf_eval, y_pred, pos_label = 1)\n",
        "\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(1, figsize = (15, 10))\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color='darkorange',\n",
        "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.0])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntxl3oL6_HQa",
        "colab_type": "text"
      },
      "source": [
        "## Réseaux de neuronnes avec Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjPbrKxp_MpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def neural_network(df_eval):\n",
        "  from keras.utils import to_categorical\n",
        "  # load the dataset but only keep the top n words, zero the rest\n",
        "  label = \"is_good_review\"\n",
        "  ignore_cols = [label, \"rate\",\"review\", \"review.cleaned\", \"id\"]\n",
        "  features = [c for c in dfshuf0.columns if c not in ignore_cols]\n",
        "  # split the data into train and test\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  X_train, X_test, y_train, y_test = train_test_split(dfshuf0[features], dfshuf0[label], test_size = 0.20, random_state = 42)\n",
        "  y_train = to_categorical(y_train, num_classes=2)\n",
        "  from keras.models import Sequential\n",
        "  from keras.layers import Dense\n",
        "  #create model\n",
        "  model = Sequential()\n",
        "  #get number of columns in training data\n",
        "  n_cols_2 = X_train.shape[1]\n",
        "  #add layers to model\n",
        "  model.add(Dense(250, activation='relu', kernel_initializer='random_normal', input_shape=(n_cols_2,)))\n",
        "  model.add(Dense(250, activation='relu', kernel_initializer='random_normal'))\n",
        "  model.add(Dense(250, activation='relu', kernel_initializer='random_normal'))\n",
        "  model.add(Dense(2, activation='softmax', kernel_initializer='random_normal'))\n",
        "  #compile model using accuracy to measure model performance\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  #train model\n",
        "  from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "  history = model.fit(X_train, y_train, epochs=150, batch_size=500)\n",
        "  from keras import losses\n",
        "  y_pred = model.predict(df_eval)\n",
        "  return y_pred\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDjEq2mY_lWm",
        "colab_type": "text"
      },
      "source": [
        "### Résultalts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmDncCBeuU2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.utils import to_categorical\n",
        "label = \"is_good_review\"\n",
        "ignore_cols = [label,\"rate\", \"review\", \"review.cleaned\",\"id\"]\n",
        "features = [c for c in dfshuf_eval.columns if c not in ignore_cols]\n",
        "X_dfshuf_eval = dfshuf_eval[features]\n",
        "y_dfshuf_eval = dfshuf_eval[label]\n",
        "y_dfshuf_eval = to_categorical(y_dfshuf_eval, num_classes=2)\n",
        "eval_predicted = neural_network(X_dfshuf_eval)\n",
        "print(mean_squared_error(eval_predicted,y_dfshuf_eval))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmXiE2fqaY1T",
        "colab_type": "text"
      },
      "source": [
        "# Modeling `rate`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAmjUxS5ariD",
        "colab_type": "text"
      },
      "source": [
        "## Prediction based on `compound`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_Gv5UnoawQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "On predit la note à l'aide du calcule de sentiments.\n",
        "Le résultat obtenu est un chiffre compris dans l'intervalle [-1;1] qu'on normalise dans [1;5]\n",
        "\"\"\"\n",
        "def predict_rate(compound): \n",
        "  final_rate = 2.5 * compound + 2.5\n",
        "  return math.ceil(final_rate)\n",
        "\n",
        "def get_score(data):\n",
        "  mean = 0\n",
        "  divisor = data.shape[0]\n",
        "  for i in range(len(data)):\n",
        "    rate = predict_rate(data['compound'][i])\n",
        "    if rate == data['rate'][i]:\n",
        "      mean += 1\n",
        "  return mean / divisor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fkn2jjDja9KN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Accuracy:\",get_score(dfshuf0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7rI6uRIbI5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Quelques exemple\n",
        "\n",
        "df_tmp = pd.DataFrame({\"rate\":dfshuf0['rate'], \"review\":dfshuf0['review'], \"compound\":dfshuf0['compound']})\n",
        "compound0 = df_tmp.iloc[0,2]\n",
        "compound1 = df_tmp.iloc[1,2]\n",
        "compound2 = df_tmp.iloc[2,2]\n",
        "compound3 = df_tmp.iloc[3,2]\n",
        "compound4 = df_tmp.iloc[4,2]\n",
        "print(\"Rate predicted:\",predict_rate(compound0))\n",
        "print(\"Rate predicted:\",predict_rate(compound1))\n",
        "print(\"Rate predicted:\",predict_rate(compound2))\n",
        "print(\"Rate predicted:\",predict_rate(compound3))\n",
        "print(\"Rate predicted:\",predict_rate(compound4))\n",
        "df_tmp.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsDqHwNw54tR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def confusion_m(data):\n",
        "  cm = [[0,0,0,0,0],\n",
        "        [0,0,0,0,0],\n",
        "        [0,0,0,0,0],\n",
        "        [0,0,0,0,0],\n",
        "        [0,0,0,0,0]]\n",
        "  for i in range(data.shape[0]):\n",
        "    rate = data.rate[i] - 1\n",
        "    rate_pred = predict_rate(data[\"compound\"][i]) - 1\n",
        "    cm[rate][rate_pred] += 1\n",
        "  return cm\n",
        "cm = confusion_m(dfshuf0)\n",
        "print(\"True prediction\")\n",
        "print(\"1:\", cm[0][0])\n",
        "print(\"2:\", cm[1][1])\n",
        "print(\"3:\", cm[2][2])\n",
        "print(\"4:\", cm[3][3])\n",
        "print(\"5:\", cm[4][4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd7ivv0PEVRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "labels = [\"1\",\"2\",\"3\",\"4\",\"5\"]\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(cm)\n",
        "plt.title('Confusion matrix du classifier')\n",
        "fig.colorbar(cax)\n",
        "ax.set_xticklabels([''] + labels)\n",
        "ax.set_yticklabels([''] + labels)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "\n",
        "for i in range(len(cm)):\n",
        "    for j in range(len(cm)):\n",
        "        plt.text(j, i, format(cm[i][j]),\n",
        "                ha=\"center\", va=\"center\",\n",
        "                color=\"white\") \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsLI5-5DYKGt",
        "colab_type": "text"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt0_6nhvqbP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logistic_regression2(df_eval):\n",
        "  # on lance la logistic regression sur les 2 dataset: dfshuf1 et dfshuf0\n",
        "  label = \"rate\"\n",
        "  ignore_cols = [label,\"is_good_review\", \"review\", \"review.cleaned\", \"id\"]\n",
        "  features = [c for c in dfshuf0.columns if c not in ignore_cols]\n",
        "  # split the data into train and test\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  X_train, X_test, y_train, y_test = train_test_split(dfshuf0[features], dfshuf0[label], test_size = 0.20, random_state = 42)\n",
        "  # train a logitstic regression classifier\n",
        "  from sklearn.pipeline import Pipeline, make_pipeline\n",
        "  from sklearn.feature_extraction.text import TfidfTransformer\n",
        "  parameters = {\n",
        "      # 'tfidftransformer__use_idf': (True, False),\n",
        "      'logisticregression__C': [0.001, 0.01, 0.1, 1, 10]\n",
        "  }\n",
        "  from sklearn.model_selection import GridSearchCV\n",
        "  pipeline = make_pipeline(LogisticRegression(solver=\"newton-cg\",multi_class='multinomial'))\n",
        "  grid_search = GridSearchCV(pipeline, parameters, verbose=1, cv=2)\n",
        "  # train Logistic regression à partir d'un grid_search\n",
        "  # ⚠︎ Le temps d'entrainement peut durer plus de 20 minutes ⚠ ︎︎\n",
        "  try:\n",
        "    grid_search.fit(X_train, y_train)\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "  y_pred = grid_search.predict(df_eval)\n",
        "  return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPC1g93yQXxE",
        "colab_type": "text"
      },
      "source": [
        "### Résultats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtDsndEzJVVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "label = \"rate\"\n",
        "ignore_cols = [label,\"is_good_review\", \"review\", \"review.cleaned\",\"id\"]\n",
        "features = [c for c in dfshuf_eval.columns if c not in ignore_cols]\n",
        "X_dfshuf_eval = dfshuf_eval[features]\n",
        "y_dfshuf_eval = dfshuf_eval[label]\n",
        "eval_predicted = logistic_regression2(X_dfshuf_eval)\n",
        "print(mean_squared_error(eval_predicted,y_dfshuf_eval))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4zsXhWoOU35",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "labels = [\"1\",\"2\",\"3\",\"4\",\"5\"]\n",
        "cm = confusion_matrix(y_dfshuf_eval, eval_predicted)\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(cm)\n",
        "plt.title('Confusion matrix')\n",
        "fig.colorbar(cax)\n",
        "ax.set_xticklabels([''] + labels)\n",
        "ax.set_yticklabels([''] + labels)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "thresh = cm.max()/2\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        plt.text(j, i, format(cm[i, j]),\n",
        "                ha=\"center\", va=\"center\",\n",
        "                color=\"white\") \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zctBgZFKJIzM",
        "colab_type": "text"
      },
      "source": [
        "## Randomforest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDCuM3ZLwhFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_forest2(df_eval):\n",
        "  label = \"rate\"\n",
        "  ignore_cols = [label, \"is_good_review\",\"review\", \"review.cleaned\", \"id\"]\n",
        "  features = [c for c in dfshuf0.columns if c not in ignore_cols]\n",
        "  # split the data into train and test\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  # split the data into train and test\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  X_train, X_test, y_train, y_test = train_test_split(dfshuf0[features], dfshuf0[label], test_size = 0.20, random_state = 42)\n",
        "  from sklearn.pipeline import Pipeline, make_pipeline\n",
        "  from sklearn.feature_extraction.text import TfidfTransformer\n",
        "  parameters = {\n",
        "    'randomforestclassifier__n_estimators':(25,50,75,100),\n",
        "    'randomforestclassifier__criterion':('entropy', 'gini')\n",
        "    }\n",
        "  from sklearn.model_selection import GridSearchCV\n",
        "  pipeline = make_pipeline(TfidfTransformer(),RandomForestClassifier())\n",
        "  grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, cv=5)\n",
        "  # train random forest classifier à partir d'un grid_search\n",
        "  grid_search.fit(X_train, y_train)\n",
        "  y_pred = grid_search.predict(df_eval)\n",
        "  return y_pred\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLJHg7AFw1jO",
        "colab_type": "text"
      },
      "source": [
        "### Résultats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJMR59_Iw29F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "label = \"rate\"\n",
        "ignore_cols = [label,\"is_good_review\", \"review\", \"review.cleaned\",\"id\"]\n",
        "features = [c for c in dfshuf_eval.columns if c not in ignore_cols]\n",
        "X_dfshuf_eval = dfshuf_eval[features]\n",
        "y_dfshuf_eval = dfshuf_eval[label]\n",
        "eval_predicted = random_forest2(X_dfshuf_eval)\n",
        "print(mean_squared_error(eval_predicted,y_dfshuf_eval))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsCUbqaJcRAo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# on montre les features importante\n",
        "feature_importances_df = pd.DataFrame({\"feature\": features, \"importance\": grid_search.best_estimator_.named_steps[\"randomforestclassifier\"].feature_importances_}).sort_values(\"importance\", ascending = False)\n",
        "feature_importances_df.head(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkGWeESwSzSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "labels = [\"1\",\"2\",\"3\",\"4\",\"5\"]\n",
        "cm = confusion_matrix(y_dfshuf_eval, eval_predicted)\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(cm)\n",
        "plt.title('Confusion matrix du classifier')\n",
        "fig.colorbar(cax)\n",
        "ax.set_xticklabels([''] + labels)\n",
        "ax.set_yticklabels([''] + labels)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "thresh = cm.max()/2\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        plt.text(j, i, format(cm[i, j]),\n",
        "                ha=\"center\", va=\"center\",\n",
        "                color=\"white\") \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Aglc1cARZYw",
        "colab_type": "text"
      },
      "source": [
        "## Kéras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5bm17iMxT5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def neural_network2(df_eval):\n",
        "  from keras.utils import to_categorical\n",
        "  # load the dataset but only keep the top n words, zero the rest\n",
        "  label = \"rate\"\n",
        "  ignore_cols = [label, \"is_good_review\",\"review\", \"review.cleaned\", \"id\"]\n",
        "  features = [c for c in dfshuf0.columns if c not in ignore_cols]\n",
        "  # split the data into train and test\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  X_train, X_test, y_train, y_test = train_test_split(dfshuf0[features], dfshuf0[label], test_size = 0.20, random_state = 42)\n",
        "  y_train = [x - 1 for x in y_train]\n",
        "  y_train = to_categorical(y_train, num_classes=5)\n",
        "  from keras.models import Sequential\n",
        "  from keras.layers import Dense\n",
        "  #create model\n",
        "  model = Sequential()\n",
        "  #get number of columns in training data\n",
        "  n_cols_2 = X_train.shape[1]\n",
        "  #add layers to model\n",
        "  model.add(Dense(250, activation='relu', kernel_initializer='random_normal', input_shape=(n_cols_2,)))\n",
        "  model.add(Dense(250, activation='relu', kernel_initializer='random_normal'))\n",
        "  model.add(Dense(250, activation='relu', kernel_initializer='random_normal'))\n",
        "  model.add(Dense(5, activation='softmax', kernel_initializer='random_normal'))\n",
        "  #compile model using accuracy to measure model performance\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  #train model\n",
        "  from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "  history = model.fit(X_train, y_train, epochs=150, batch_size=500)\n",
        "  \n",
        "  from keras import losses\n",
        "  y_pred = model.predict(df_eval)\n",
        "  return y_pred\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBfMI521xhlE",
        "colab_type": "text"
      },
      "source": [
        "### Résultats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfCbnNvkxjs6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "label = \"rate\"\n",
        "ignore_cols = [label,\"is_good_review\", \"review\", \"review.cleaned\",\"id\"]\n",
        "features = [c for c in dfshuf_eval.columns if c not in ignore_cols]\n",
        "X_dfshuf_eval = dfshuf_eval[features]\n",
        "y_dfshuf_eval = dfshuf_eval[label]\n",
        "\n",
        "y_dfshuf_eval = [x - 1 for x in dfshuf_eval.rate]\n",
        "y_dfshuf_eval = to_categorical(y_dfshuf_eval, num_classes=5)\n",
        "eval_predicted = neural_network2(X_dfshuf_eval)\n",
        "print(mean_squared_error(eval_predicted,y_dfshuf_eval))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}